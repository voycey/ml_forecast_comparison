{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BxRQm--pvrL",
    "outputId": "502bdeb9-702e-4b60-95df-9b0c8a1aa898",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "!pip install seaborn[stats] matplotlib tensorflow numpy scikit-learn pandas\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "e5Ha6JdoQgpR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/PJM_Load_hourly.csv\")\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "print(f\"MAX Datetime: \" + str(max(df['Datetime'])))\n",
    "print(f\"MIN Datetime: \" + str(min(df['Datetime'])))\n",
    "\n",
    "df.set_index('Datetime', inplace=True)\n",
    "data = df['PJM_Load_MW'].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Function to create seqences\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw-1):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    "\n",
    "# # Define sequence length and create sequences\n",
    "# seq_length = 24  # You can adjust this\n",
    "# sequences = create_inout_sequences(data_normalized, seq_length)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# X, y = [], []\n",
    "# for seq, label in sequences:\n",
    "#     X.append(seq)\n",
    "#     y.append(label)\n",
    "# X = np.array(X).reshape(-1, seq_length, 1)\n",
    "# y = np.array(y).reshape(-1, 1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCA8RZ-_p0A0",
    "outputId": "5c5ff0ab-52c7-4ddc-c70e-28738d04ed39",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Extend sequences to predict further into the future\n",
    "seq_length = 24 * 7 * 2  # Two weeks of historical data for each sequence\n",
    "prediction_length = 24 * 7  # Predict one week into the future\n",
    "\n",
    "sequences = create_inout_sequences(data_normalized, seq_length)\n",
    "\n",
    "# Split data into train and test sets for model training\n",
    "# Ensure that the test set is the very last part of your data\n",
    "train_sequences = sequences[:-prediction_length]  # Exclude the last week from training\n",
    "test_sequences = sequences[-prediction_length:]  # Last week for testing\n",
    "\n",
    "X_train, y_train = zip(*train_sequences)\n",
    "X_test, y_test = zip(*test_sequences)\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, seq_length, 1)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "X_test = np.array(X_test).reshape(-1, seq_length, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ],
   "metadata": {
    "id": "UvvQlw7cwRtu",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    LSTM(100, input_shape=(seq_length, 1), return_sequences=False),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ],
   "metadata": {
    "id": "RWrqeQ1np13x",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHBgP76-p2l0",
    "outputId": "66d6b778-7f9b-446a-cf44-364c7d860d56",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred)"
   ],
   "metadata": {
    "id": "LmOuKNDTp4sn",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select the last 200 entries for both actual and predicted data\n",
    "last_entries = 200\n",
    "test_dates = df.index[-len(y_test):]  # Assumes df.index has been maintained correctly\n",
    "actual_data = y_test_rescaled[-last_entries:]\n",
    "predicted_data = y_pred_rescaled[-last_entries:]\n",
    "test_dates_last_200 = test_dates[-last_entries:]\n",
    "\n",
    "# Plot settings\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Plot actual test data\n",
    "plt.plot(test_dates_last_200, actual_data, label='Actual Test Data', color='orange', alpha=0.75)\n",
    "\n",
    "# Plot predictions with dashed line\n",
    "plt.plot(test_dates_last_200, predicted_data, label='Predictions', color='green', linestyle='--', alpha=0.75)\n",
    "\n",
    "# Calculate and plot confidence intervals (assuming normality for demonstration)\n",
    "confidence_interval = np.std(predicted_data - actual_data) * 1.96\n",
    "lower_bounds = (predicted_data - confidence_interval).flatten()\n",
    "upper_bounds = (predicted_data + confidence_interval).flatten()\n",
    "\n",
    "plt.fill_between(test_dates_last_200, lower_bounds, upper_bounds, color='green', alpha=0.2)\n",
    "\n",
    "plt.title('Time Series Forecast: Actual vs Prediction (Last 200 Entries)')\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('PJM Load MW')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "L6IQx5nap6mB",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def iterative_forecasts(model, initial_sequence, n_steps):\n",
    "    \"\"\"\n",
    "    Generates future values using the model by recursively using the output as the next input.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained Keras model.\n",
    "    - initial_sequence: The last known data sequence to start predictions from.\n",
    "    - n_steps: Number of future steps to predict.\n",
    "\n",
    "    Returns:\n",
    "    - An array of predictions.\n",
    "    \"\"\"\n",
    "    forecast = initial_sequence.copy()  # Copy to avoid altering the original data\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        # Predict the next step\n",
    "        next_step = model.predict(forecast.reshape(1, seq_length, 1))\n",
    "        predictions.append(next_step.flatten()[0])  # Store the predicted value\n",
    "\n",
    "        # Update the forecast array\n",
    "        forecast = np.roll(forecast, -1)  # Shift everything one step to the left\n",
    "        forecast[-1] = next_step  # Insert the predicted value as the last item\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Using the last sequence of the training set to predict forward\n",
    "last_sequence = X_train[-1].reshape(seq_length, 1)\n",
    "n_future_steps = 24 * 7  # Predict one week ahead\n",
    "future_predictions = iterative_forecasts(model, last_sequence, n_future_steps)\n"
   ],
   "metadata": {
    "id": "uyTcAjBk07rl",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Rescale the predictions back to the original scale\n",
    "future_predictions_rescaled = scaler.inverse_transform(future_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Prepare data for plotting\n",
    "future_dates = pd.date_range(start=df.index[-1], periods=len(future_predictions) + 1, freq='H')[1:]\n",
    "historical_dates = df.index[-seq_length:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Historical data for the last two weeks\n",
    "plt.plot(historical_dates, scaler.inverse_transform(X_train[-1]), label='Historical Data', color='blue')\n",
    "\n",
    "# Future predictions beyond data boundary\n",
    "plt.plot(future_dates, future_predictions_rescaled, label='Future Predictions', color='red')\n",
    "\n",
    "plt.title('Forecast with Future Prediction')\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('PJM Load MW')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "LEH-U9lk00Zk",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
